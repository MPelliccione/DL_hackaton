{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch_geometric\n","metadata":{"id":"xSkgt1zf-raF","outputId":"59f4a52f-5eb4-41e5-9fba-07432989fe78","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:05:49.743246Z","iopub.execute_input":"2025-05-27T16:05:49.743547Z","iopub.status.idle":"2025-05-27T16:05:56.022741Z","shell.execute_reply.started":"2025-05-27T16:05:49.743511Z","shell.execute_reply":"2025-05-27T16:05:56.021887Z"}},"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!git clone --branch baselineCe https://github.com/Graph-Classification-Noisy-Label/hackaton.git\n","metadata":{"id":"5oR2D2Us-xSQ","outputId":"7086cadf-a7fe-4d75-f271-6339bee8164d","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:05:56.023767Z","iopub.execute_input":"2025-05-27T16:05:56.024108Z","iopub.status.idle":"2025-05-27T16:06:00.240888Z","shell.execute_reply.started":"2025-05-27T16:05:56.024075Z","shell.execute_reply":"2025-05-27T16:06:00.239953Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'hackaton'...\nremote: Enumerating objects: 81, done.\u001b[K\nremote: Counting objects: 100% (4/4), done.\u001b[K\nremote: Compressing objects: 100% (3/3), done.\u001b[K\nremote: Total 81 (delta 1), reused 1 (delta 1), pack-reused 77 (from 1)\u001b[K\nReceiving objects: 100% (81/81), 105.83 MiB | 43.84 MiB/s, done.\nResolving deltas: 100% (13/13), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%cd hackaton/","metadata":{"id":"tEhfPly6-7UK","outputId":"3078ee06-6312-4fca-f5f9-888fa628c80a","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:06:00.241722Z","iopub.execute_input":"2025-05-27T16:06:00.241969Z","iopub.status.idle":"2025-05-27T16:06:00.249380Z","shell.execute_reply.started":"2025-05-27T16:06:00.241944Z","shell.execute_reply":"2025-05-27T16:06:00.248549Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/hackaton\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!gdown --folder https://drive.google.com/drive/folders/1Gf0mFRaqg_-cMAOUCkZvIemTcEpzh4XF?usp=sharing -O datasets\n","metadata":{"id":"PxBvwB0_6xI8","outputId":"5933387c-2cfb-474f-d842-f36a3e2d2a73","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:06:00.251617Z","iopub.execute_input":"2025-05-27T16:06:00.251869Z","iopub.status.idle":"2025-05-27T16:06:48.716762Z","shell.execute_reply.started":"2025-05-27T16:06:00.251826Z","shell.execute_reply":"2025-05-27T16:06:48.715776Z"}},"outputs":[{"name":"stdout","text":"Retrieving folder contents\nRetrieving folder 1pjSkW1F77JobB9WM0D6upyV4MVAh-Bhh A\nProcessing file 1V6fMoOAz1PmmX2J2sC6odnX8aHvsLkXI test.json.gz\nProcessing file 1Mr9pkFhefAY-kvByNDQO1hkPFCrWrbVT train.json.gz\nRetrieving folder 1MWCcdJHVxpsDkduapri9NCB7SEtj8bcS B\nProcessing file 1--jQFe8IrzBy9POUAVdyjjjYeJoIv-ww test.json.gz\nProcessing file 1QGpZ3tEN693onLtNKpVCfgNuurjhxiNK train.json.gz\nRetrieving folder 1DJ0itapAg68xT4ohngXeLSN4lL9o6aPV C\nProcessing file 1vhelRWElU7h4LMdzqP7Ky85QKKQ188MD test.json.gz\nProcessing file 1Xz59-7TJ2a-hbSB40ZVg86pR0_7njEgY train.json.gz\nRetrieving folder 1pFJqHvELSrcmF9M0Op3qncGSohZq6lmU D\nProcessing file 1xS_NWAMf-6BSLzzZwUWbnClJqLXll6iL test.json.gz\nProcessing file 1bTRtEZvLQsqTRotd1V_tUtBB6j6wsIfl train.json.gz\nRetrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1V6fMoOAz1PmmX2J2sC6odnX8aHvsLkXI\nFrom (redirected): https://drive.google.com/uc?id=1V6fMoOAz1PmmX2J2sC6odnX8aHvsLkXI&confirm=t&uuid=daa5bc93-6691-43a9-9a3a-6b9053b64315\nTo: /kaggle/working/hackaton/datasets/A/test.json.gz\n100%|██████████████████████████████████████| 92.4M/92.4M [00:02<00:00, 42.0MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1Mr9pkFhefAY-kvByNDQO1hkPFCrWrbVT\nFrom (redirected): https://drive.google.com/uc?id=1Mr9pkFhefAY-kvByNDQO1hkPFCrWrbVT&confirm=t&uuid=4f79965f-e6ee-4a14-8782-3068101734a1\nTo: /kaggle/working/hackaton/datasets/A/train.json.gz\n100%|█████████████████████████████████████████| 465M/465M [00:02<00:00, 160MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1--jQFe8IrzBy9POUAVdyjjjYeJoIv-ww\nFrom (redirected): https://drive.google.com/uc?id=1--jQFe8IrzBy9POUAVdyjjjYeJoIv-ww&confirm=t&uuid=13335bc2-8396-4ca0-b867-6fe6eafd05ff\nTo: /kaggle/working/hackaton/datasets/B/test.json.gz\n100%|███████████████████████████████████████| 63.0M/63.0M [00:00<00:00, 175MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1QGpZ3tEN693onLtNKpVCfgNuurjhxiNK\nFrom (redirected): https://drive.google.com/uc?id=1QGpZ3tEN693onLtNKpVCfgNuurjhxiNK&confirm=t&uuid=90bc5e8f-e0e0-4c38-9d52-661754fd389f\nTo: /kaggle/working/hackaton/datasets/B/train.json.gz\n100%|█████████████████████████████████████████| 223M/223M [00:01<00:00, 121MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1vhelRWElU7h4LMdzqP7Ky85QKKQ188MD\nFrom (redirected): https://drive.google.com/uc?id=1vhelRWElU7h4LMdzqP7Ky85QKKQ188MD&confirm=t&uuid=fbf222d1-4f6e-45af-8c91-f843fe0539b8\nTo: /kaggle/working/hackaton/datasets/C/test.json.gz\n100%|███████████████████████████████████████| 60.5M/60.5M [00:00<00:00, 134MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1Xz59-7TJ2a-hbSB40ZVg86pR0_7njEgY\nFrom (redirected): https://drive.google.com/uc?id=1Xz59-7TJ2a-hbSB40ZVg86pR0_7njEgY&confirm=t&uuid=b98da7a7-7437-4f6c-bb4c-b30c1765a597\nTo: /kaggle/working/hackaton/datasets/C/train.json.gz\n100%|█████████████████████████████████████████| 308M/308M [00:02<00:00, 113MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1xS_NWAMf-6BSLzzZwUWbnClJqLXll6iL\nFrom (redirected): https://drive.google.com/uc?id=1xS_NWAMf-6BSLzzZwUWbnClJqLXll6iL&confirm=t&uuid=3484463d-6e75-4b3c-a926-9c975aba2d4d\nTo: /kaggle/working/hackaton/datasets/D/test.json.gz\n100%|███████████████████████████████████████| 94.0M/94.0M [00:00<00:00, 169MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1bTRtEZvLQsqTRotd1V_tUtBB6j6wsIfl\nFrom (redirected): https://drive.google.com/uc?id=1bTRtEZvLQsqTRotd1V_tUtBB6j6wsIfl&confirm=t&uuid=b68f81e8-af3d-4533-9137-62c32f949db6\nTo: /kaggle/working/hackaton/datasets/D/train.json.gz\n100%|████████████████████████████████████████| 439M/439M [00:06<00:00, 70.8MB/s]\nDownload completed\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!ls -lh datasets","metadata":{"id":"1rockhiQ7Nny","outputId":"2cd2e6f4-5f8f-4a62-f0ec-53e6fc78c9b7","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:06:48.718457Z","iopub.execute_input":"2025-05-27T16:06:48.718726Z","iopub.status.idle":"2025-05-27T16:06:48.841476Z","shell.execute_reply.started":"2025-05-27T16:06:48.718703Z","shell.execute_reply":"2025-05-27T16:06:48.840391Z"}},"outputs":[{"name":"stdout","text":"total 16K\ndrwxr-xr-x 2 root root 4.0K May 27 16:06 A\ndrwxr-xr-x 2 root root 4.0K May 27 16:06 B\ndrwxr-xr-x 2 root root 4.0K May 27 16:06 C\ndrwxr-xr-x 2 root root 4.0K May 27 16:06 D\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def add_zeros(data):\n        if data.x is None:\n            # Change dtype to torch.float\n            data.x = torch.ones((data.num_nodes, 8), dtype=torch.float)\n        return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:13:43.912388Z","iopub.execute_input":"2025-05-27T16:13:43.912765Z","iopub.status.idle":"2025-05-27T16:13:43.917300Z","shell.execute_reply.started":"2025-05-27T16:13:43.912735Z","shell.execute_reply":"2025-05-27T16:13:43.916300Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport logging\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom tqdm import tqdm\nfrom torch_geometric.loader import DataLoader\nfrom torch.utils.data import random_split\n# Load utility functions from cloned repository\nfrom src.loadData import GraphDataset\nfrom src.utils import set_seed\nfrom src.models import GNN\nimport argparse\n\n# Set the random seed\nset_seed()\n\n\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_mean_pool, BatchNorm","metadata":{"id":"lAQuCuIoBbq5","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:06:48.848587Z","iopub.execute_input":"2025-05-27T16:06:48.848795Z","iopub.status.idle":"2025-05-27T16:06:56.886287Z","shell.execute_reply.started":"2025-05-27T16:06:48.848777Z","shell.execute_reply":"2025-05-27T16:06:56.885319Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool\nfrom torch_geometric.utils import degree\nimport math\n\nclass MLPLayer(nn.Module):\n    \"\"\"Multi-layer perceptron layer with batch normalization and dropout\"\"\"\n    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.1):\n        super(MLPLayer, self).__init__()\n        self.linear1 = nn.Linear(input_dim, hidden_dim)\n        self.linear2 = nn.Linear(hidden_dim, output_dim)\n        self.bn = nn.BatchNorm1d(hidden_dim)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        x = self.linear1(x)\n        x = self.bn(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n        x = self.linear2(x)\n        return x\n\nclass GINPlusLayer(nn.Module):\n    \"\"\"Enhanced GIN layer with edge features and improved aggregation\"\"\"\n    def __init__(self, in_dim, hidden_dim, edge_dim, dropout=0.1):\n        super(GINPlusLayer, self).__init__()\n        self.in_dim = in_dim\n        self.hidden_dim = hidden_dim\n        self.edge_dim = edge_dim\n        \n        # Edge feature transformation\n        self.edge_encoder = nn.Sequential(\n            nn.Linear(edge_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout)\n        )\n        \n        # Node feature transformation\n        self.node_encoder = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout)\n        )\n        \n        # MLP for aggregation (as per GIN)\n        self.mlp = MLPLayer(hidden_dim, hidden_dim * 2, hidden_dim, dropout)\n        \n        # Learnable epsilon parameter\n        self.eps = nn.Parameter(torch.zeros(1))\n        \n        # Attention mechanism for edge-aware aggregation\n        self.attention = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, 1),\n            nn.LeakyReLU(0.2)\n        )\n        \n    def forward(self, x, edge_index, edge_attr, virtual_node=None):\n        # Transform node features\n        x_transformed = self.node_encoder(x)\n        \n        # Transform edge features\n        edge_feat = self.edge_encoder(edge_attr)\n        \n        # Message passing with edge-aware attention\n        row, col = edge_index\n        \n        # Compute attention weights\n        node_i = x_transformed[row]  # Source nodes\n        node_j = x_transformed[col]  # Target nodes\n        \n        # Combine node and edge features for attention\n        attention_input = torch.cat([node_i + edge_feat, node_j], dim=-1)\n        attention_weights = self.attention(attention_input)\n        attention_weights = F.softmax(attention_weights, dim=0)\n        \n        # Weighted message aggregation\n        messages = (node_j + edge_feat) * attention_weights\n        \n        # Aggregate messages for each node\n        out = torch.zeros_like(x_transformed)\n        out.index_add_(0, row, messages)\n        \n        # Add virtual node contribution if provided\n        if virtual_node is not None:\n            out = out + virtual_node.expand_as(out)\n        \n        # Apply GIN update rule: (1 + eps) * x + aggregated_messages\n        out = (1 + self.eps) * x_transformed + out\n        \n        # Apply MLP\n        out = self.mlp(out)\n        \n        return out\n\nclass VirtualNode(nn.Module):\n    \"\"\"Virtual node implementation for global graph representation\"\"\"\n    def __init__(self, hidden_dim, dropout=0.1):\n        super(VirtualNode, self).__init__()\n        self.hidden_dim = hidden_dim\n        \n        # Virtual node embedding\n        self.virtual_emb = nn.Parameter(torch.randn(1, hidden_dim))\n        \n        # MLPs for virtual node updates\n        self.vn_mlp = MLPLayer(hidden_dim, hidden_dim * 2, hidden_dim, dropout)\n        self.node_mlp = MLPLayer(hidden_dim, hidden_dim * 2, hidden_dim, dropout)\n        \n        # Attention for virtual node interaction\n        self.vn_attention = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, 1)\n        )\n        \n    def forward(self, x, batch):\n        batch_size = batch.max().item() + 1\n        \n        # Aggregate node features per graph for virtual node update\n        vn_input = global_mean_pool(x, batch)  # [batch_size, hidden_dim]\n        \n        # Update virtual node representation\n        vn_feat = self.virtual_emb.expand(batch_size, -1)\n        vn_updated = self.vn_mlp(vn_feat + vn_input)\n        \n        # Compute attention between virtual node and regular nodes\n        vn_expanded = vn_updated[batch]  # Expand to match node dimensions\n        attention_input = torch.cat([x, vn_expanded], dim=-1)\n        attention_weights = torch.softmax(self.vn_attention(attention_input), dim=0)\n        \n        # Apply attention to virtual node contribution\n        vn_contribution = vn_expanded * attention_weights\n        \n        return vn_contribution, vn_updated\n\nclass NoiseFilter(nn.Module):\n    \"\"\"Noise filtering module for handling noisy labels\"\"\"\n    def __init__(self, hidden_dim, num_classes, confidence_threshold=0.8):\n        super(NoiseFilter, self).__init__()\n        self.confidence_threshold = confidence_threshold\n        self.num_classes = num_classes\n        \n        # Confidence estimation network\n        self.confidence_net = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_dim // 2, 1),\n            nn.Sigmoid()\n        )\n        \n        # Label correction network\n        self.correction_net = nn.Sequential(\n            nn.Linear(hidden_dim + num_classes, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_dim, num_classes)\n        )\n        \n    def forward(self, graph_emb, predictions, labels=None):\n        # Estimate confidence in predictions\n        confidence = self.confidence_net(graph_emb)\n        \n        if labels is not None and self.training:\n            # During training, identify potentially noisy samples\n            pred_probs = F.softmax(predictions, dim=-1)\n            max_prob, pred_labels = torch.max(pred_probs, dim=-1)\n            \n            # Samples with low confidence or disagreement with labels are potentially noisy\n            label_agreement = (pred_labels == labels).float().unsqueeze(-1)\n            noise_score = 1.0 - (confidence * label_agreement)\n            \n            # For high noise score samples, attempt label correction\n            correction_input = torch.cat([graph_emb, F.one_hot(labels, self.num_classes).float()], dim=-1)\n            corrected_logits = self.correction_net(correction_input)\n            \n            # Blend original and corrected predictions based on noise score\n            final_logits = (1 - noise_score) * predictions + noise_score * corrected_logits\n            \n            return final_logits, confidence, noise_score\n        else:\n            return predictions, confidence, None\n\nclass GINPlusModel(nn.Module):\n    \"\"\"Complete GIN+ model with virtual node and noise filtering\"\"\"\n    def __init__(self, in_dim=8, edge_dim=8, hidden_dim=300, out_classes=6, \n                 num_layers=5, dropout=0.1, use_virtual_node=True, \n                 confidence_threshold=0.8):\n        super(GINPlusModel, self).__init__()\n        \n        self.num_layers = num_layers\n        self.hidden_dim = hidden_dim\n        self.use_virtual_node = use_virtual_node\n        self.dropout = dropout\n        \n        # Input feature transformation\n        self.input_encoder = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout)\n        )\n        \n        # GIN+ layers\n        self.gin_layers = nn.ModuleList([\n            GINPlusLayer(hidden_dim, hidden_dim, edge_dim, dropout)\n            for _ in range(num_layers)\n        ])\n        \n        # Virtual node\n        if use_virtual_node:\n            self.virtual_node = VirtualNode(hidden_dim, dropout)\n        \n        # Graph-level pooling\n        self.pool = [\n            global_add_pool,\n            global_mean_pool,\n            global_max_pool\n        ]\n        \n        # Final classifier\n        pooled_dim = hidden_dim * 3  # Concatenation of add, mean, max pooling\n        self.classifier = nn.Sequential(\n            nn.Linear(pooled_dim, hidden_dim),\n            nn.BatchNorm1d(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.BatchNorm1d(hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, out_classes)\n        )\n        \n        # Noise filtering\n        self.noise_filter = NoiseFilter(pooled_dim, out_classes, confidence_threshold)\n        \n        # Initialize parameters\n        self._init_parameters()\n        \n    def _init_parameters(self):\n        \"\"\"Initialize model parameters\"\"\"\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm1d):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n    \n    def forward(self, x, edge_index, edge_attr, batch, labels=None):\n        # Input encoding\n        x = self.input_encoder(x)\n        \n        # GIN+ layers with virtual node\n        vn_contribution = None\n        for i, gin_layer in enumerate(self.gin_layers):\n            if self.use_virtual_node:\n                if i == 0:\n                    # Initialize virtual node contribution\n                    vn_contribution, _ = self.virtual_node(x, batch)\n                else:\n                    # Update virtual node\n                    vn_contribution, _ = self.virtual_node(x, batch)\n            \n            x = gin_layer(x, edge_index, edge_attr, vn_contribution)\n            \n            # Apply residual connection and layer normalization\n            if i > 0:\n                x = x + x_prev\n            x_prev = x\n        \n        # Graph-level representation\n        graph_emb_list = []\n        for pool_fn in self.pool: # Iterate through the list of functions\n            graph_emb_list.append(pool_fn(x, batch))\n\n        graph_emb = torch.cat(graph_emb_list, dim=-1)\n        \n        # Classification\n        logits = self.classifier(graph_emb)\n        \n        # Noise filtering\n        filtered_logits, confidence, noise_score = self.noise_filter(graph_emb, logits, labels)\n        \n        return {\n            'logits': filtered_logits,\n            'confidence': confidence,\n            'noise_score': noise_score,\n            'graph_embedding': graph_emb\n        }\n    \n    def get_embeddings(self, x, edge_index, edge_attr, batch):\n        \"\"\"Get graph embeddings without classification\"\"\"\n        with torch.no_grad():\n            output = self.forward(x, edge_index, edge_attr, batch)\n            return output['graph_embedding']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:13:47.134818Z","iopub.execute_input":"2025-05-27T16:13:47.135195Z","iopub.status.idle":"2025-05-27T16:13:47.161972Z","shell.execute_reply.started":"2025-05-27T16:13:47.135167Z","shell.execute_reply":"2025-05-27T16:13:47.160788Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"cross_entropy_val = nn.CrossEntropyLoss\n\nmean = 1e-8\nstd  = 1e-9\nencoder_features =512\ntotal_epochs = 5\n\nclass ncodLoss(nn.Module):\n    def __init__(self, labels, n=50000, C=100, ratio_consistency=0, ratio_balance=0):\n        super(ncodLoss, self).__init__()\n\n        self.C = C\n        self.USE_CUDA = torch.cuda.is_available()\n        self.n = n\n\n        self.ratio_consistency = ratio_consistency\n        self.ratio_balance = ratio_balance\n\n\n        self.u = nn.Parameter(torch.empty(n, 1, dtype=torch.float32))\n        self.init_param(mean=mean,std=std)\n\n        self.beginning = True\n        self.prev_phi_x_i = torch.rand((n, encoder_features))\n        self.phi_c = torch.rand((C, encoder_features))\n        self.labels = labels\n        self.bins = []\n\n        for i in range(0, C):\n            self.bins.append(np.where(self.labels == i)[0])\n\n\n    def init_param(self, mean= 1e-8, std= 1e-9):\n        torch.nn.init.normal_(self.u, mean=mean, std=std)\n\n\n    def forward(self, index, f_x_i, y, phi_x_i, flag, epoch):\n\n        if len(f_x_i) > len(index):\n            f_x_i_1, f_x_i_2 = torch.chunk(f_x_i, 2)\n            phi_x_i_1, phi_x_i_2 = torch.chunk(phi_x_i, 2)\n        else:\n            f_x_i_1 = f_x_i\n            phi_x_i_1 = phi_x_i\n\n        eps = 1e-4\n\n        u = self.u.to(index.device)[index]\n\n\n\n        if (flag == 0):\n            if self.beginning:\n                percent = math.ceil((50 - (50 / total_epochs) * epoch) + 50)\n                for i in range(0, len(self.bins)):\n                    class_u = self.u.detach()[self.bins[i]]\n                    bottomK = int((len(class_u) / 100) * percent)\n                    important_indexs = torch.topk(class_u, bottomK, largest=False, dim=0)[1]\n                    self.phi_c[i] = torch.mean(self.prev_phi_x_i[self.bins[i]][important_indexs.view(-1)],\n                                                      dim=0)\n\n            phi_c_norm = self.phi_c.norm(p=2, dim=1, keepdim=True)\n            h_c_bar = self.phi_c.div(phi_c_norm)\n            self.h_c_bar_T = torch.transpose(h_c_bar, 0, 1)\n            self.beginning = True\n\n        self.prev_phi_x_i[index] = phi_x_i_1.detach()\n\n        f_x_softmax = F.softmax(f_x_i_1, dim=1)\n\n        phi_x_i_1_norm = phi_x_i_1.detach().norm(p=2, dim=1, keepdim=True)\n        h_i = phi_x_i_1.detach().div(phi_x_i_1_norm)\n\n        y_bar = torch.mm(h_i, self.h_c_bar_T)\n        y_bar = y_bar * y\n        y_bar_max = (y_bar > 0.000).type(torch.float32)\n        y_bar = y_bar * y_bar_max\n\n        u = u * y\n\n        f_x_softmax = torch.clamp((f_x_softmax + u.detach()), min=eps, max=1.0)\n        L1 = torch.mean(-torch.sum((y_bar) * torch.log(f_x_softmax), dim=1))\n\n        y_hat = self.soft_to_hard(f_x_i_1.detach())\n\n        L2 = F.MSE_loss((y_hat + u), y, reduction='sum') / len(y)\n        L1 += L2\n\n\n\n        if self.ratio_balance > 0:\n            avg_prediction = torch.mean(f_x_softmax, dim=0)\n            prior_distr = 1.0 / self.C * torch.ones_like(avg_prediction)\n\n            avg_prediction = torch.clamp(avg_prediction, min=eps, max=1.0)\n\n            balance_kl = torch.mean(-(prior_distr * torch.log(avg_prediction)).sum(dim=0))\n\n            L1 += self.ratio_balance * balance_kl\n\n        if (len(f_x_i) > len(index)) and (self.ratio_consistency > 0):\n            consistency_loss = self.consistency_loss( f_x_i_1, f_x_i_2)\n\n            L1 += self.ratio_consistency * torch.mean(consistency_loss)\n\n\n        return L1\n\n\n    def consistency_loss(self,  f_x_i_1, f_x_i_2):\n        preds1 = F.softmax( f_x_i_1, dim=1).detach()\n        preds2 = F.log_softmax(f_x_i_2, dim=1)\n        loss_kldiv = F.kl_div(preds2, preds1, reduction='none')\n        loss_kldiv = torch.sum(loss_kldiv, dim=1)\n        return loss_kldiv\n\n    def soft_to_hard(self, x):\n        with torch.no_grad():\n            return (torch.zeros(len(x), self.C)).cuda().scatter_(1, (x.argmax(dim=1)).view(-1, 1), 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:13:52.656773Z","iopub.execute_input":"2025-05-27T16:13:52.657141Z","iopub.status.idle":"2025-05-27T16:13:52.671816Z","shell.execute_reply.started":"2025-05-27T16:13:52.657110Z","shell.execute_reply":"2025-05-27T16:13:52.670953Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Wraps ncodLoss to accept model output dict\nclass NcodLossWrapper(nn.Module):\n    def __init__(self, ncod_loss):\n        super().__init__()\n        self.ncod_loss = ncod_loss\n\n    def forward(self, outputs, labels, index=None, flag=0, epoch=0):\n        logits = outputs['logits']\n        phi_x_i = outputs['graph_embedding']\n        C = logits.size(1)\n        y_onehot = F.one_hot(labels, num_classes=C).float()\n        if index is None:\n            index = torch.arange(labels.size(0), device=labels.device)\n        return self.ncod_loss(index, logits, y_onehot, phi_x_i, flag, epoch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:13:57.263224Z","iopub.execute_input":"2025-05-27T16:13:57.263509Z","iopub.status.idle":"2025-05-27T16:13:57.269082Z","shell.execute_reply.started":"2025-05-27T16:13:57.263488Z","shell.execute_reply":"2025-05-27T16:13:57.267963Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Custom loss function for noisy labels\nclass NoisyLabelLoss(nn.Module):\n    \"\"\"Loss function that accounts for label noise\"\"\"\n    def __init__(self, alpha=0.1, beta=0.5):\n        super(NoisyLabelLoss, self).__init__()\n        self.alpha = alpha  # Weight for confidence regularization\n        self.beta = beta    # Weight for noise penalty\n        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n\n    def forward(self, outputs, labels):\n        logits = outputs['logits']\n        confidence = outputs['confidence'].squeeze()\n        noise_score = outputs.get('noise_score', None)\n\n        # Standard cross-entropy loss\n        ce_loss = self.ce_loss(logits, labels) # Pass logits here\n\n        # Weight loss by confidence (down-weight low-confidence samples)\n        weighted_ce = ce_loss * confidence\n\n        # Confidence regularization (encourage high confidence on clean samples)\n        conf_reg = -torch.log(confidence + 1e-8)\n\n        # Noise penalty\n        noise_penalty = 0.0\n        if noise_score is not None:\n            noise_penalty = torch.mean(noise_score.squeeze())\n\n        total_loss = (torch.mean(weighted_ce) +\n                     self.alpha * torch.mean(conf_reg) +\n                     self.beta * noise_penalty)\n\n        return total_loss\n        return total_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:06:56.958198Z","iopub.execute_input":"2025-05-27T16:06:56.958513Z","iopub.status.idle":"2025-05-27T16:06:56.981326Z","shell.execute_reply.started":"2025-05-27T16:06:56.958484Z","shell.execute_reply":"2025-05-27T16:06:56.980548Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    for data in tqdm(data_loader, desc=\"Iterating training graphs\", unit=\"batch\"):\n        data = data.to(device)\n        optimizer.zero_grad()\n        output = model(data.x, data.edge_index, data.edge_attr, data.batch, data.y)\n        loss = criterion(output, data.y, index=data.idx if hasattr(data, 'idx') else None, flag=0, epoch=current_epoch)\n        loss.backward()\n        optimizer.step()\n        torch.cuda.empty_cache()\n        total_loss += loss.item()\n        pred = output['logits'].argmax(dim=1)\n        correct += (pred == data.y).sum().item()\n        total += data.y.size(0)\n\n    # Save checkpoints if required\n    if save_checkpoints:\n        checkpoint_file = f\"{checkpoint_path}_epoch_{current_epoch + 1}.pth\"\n        torch.save(model.state_dict(), checkpoint_file)\n        print(f\"Checkpoint saved at {checkpoint_file}\")\n\n    return total_loss / len(data_loader),  correct / total","metadata":{"id":"3jKvoQYI9Zbc","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:14:00.555210Z","iopub.execute_input":"2025-05-27T16:14:00.555548Z","iopub.status.idle":"2025-05-27T16:14:00.561927Z","shell.execute_reply.started":"2025-05-27T16:14:00.555520Z","shell.execute_reply":"2025-05-27T16:14:00.560947Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def evaluate(data_loader, model, device, calculate_accuracy=False):\n    model.eval()\n    correct = 0\n    total = 0\n    predictions = []\n    total_loss = 0\n    criterion = torch.nn.CrossEntropyLoss()\n    with torch.no_grad():\n        for data in tqdm(data_loader, desc=\"Iterating eval graphs\", unit=\"batch\"):\n            data = data.to(device)\n            output = model(data.x, data.edge_index, data.edge_attr, data.batch, data.y if calculate_accuracy else None)\n            pred = output['logits'].argmax(dim=1)\n            \n            if calculate_accuracy:\n                correct += (pred == data.y).sum().item()\n                total += data.y.size(0)\n                total_loss += criterion(output['logits'], data.y).item()\n            else:\n                predictions.extend(pred.cpu().numpy())\n    if calculate_accuracy:\n        accuracy = correct / total\n        return  total_loss / len(data_loader),accuracy\n    return predictions","metadata":{"id":"8peFiIS19ZpK","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:14:02.143532Z","iopub.execute_input":"2025-05-27T16:14:02.143828Z","iopub.status.idle":"2025-05-27T16:14:02.150086Z","shell.execute_reply.started":"2025-05-27T16:14:02.143805Z","shell.execute_reply":"2025-05-27T16:14:02.149054Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def save_predictions(predictions, test_path):\n    script_dir = os.getcwd() \n    submission_folder = os.path.join(script_dir, \"submission\")\n    test_dir_name = os.path.basename(os.path.dirname(test_path))\n    \n    os.makedirs(submission_folder, exist_ok=True)\n    \n    output_csv_path = os.path.join(submission_folder, f\"testset_{test_dir_name}.csv\")\n    \n    test_graph_ids = list(range(len(predictions)))\n    output_df = pd.DataFrame({\n        \"id\": test_graph_ids,\n        \"pred\": predictions\n    })\n    \n    output_df.to_csv(output_csv_path, index=False)\n    print(f\"Predictions saved to {output_csv_path}\")","metadata":{"id":"WanuZKxy9Zs-","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:14:04.023662Z","iopub.execute_input":"2025-05-27T16:14:04.023971Z","iopub.status.idle":"2025-05-27T16:14:04.029174Z","shell.execute_reply.started":"2025-05-27T16:14:04.023947Z","shell.execute_reply":"2025-05-27T16:14:04.028356Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def plot_training_progress(train_losses, train_accuracies, output_dir):\n    epochs = range(1, len(train_losses) + 1)\n    plt.figure(figsize=(12, 6))\n\n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_losses, label=\"Training Loss\", color='blue')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training Loss per Epoch')\n\n    # Plot accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\", color='green')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Training Accuracy per Epoch')\n\n    # Save plots in the current directory\n    os.makedirs(output_dir, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, \"training_progress.png\"))\n    plt.close()","metadata":{"id":"uyHIJS5U9ZzB","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:14:05.651901Z","iopub.execute_input":"2025-05-27T16:14:05.652241Z","iopub.status.idle":"2025-05-27T16:14:05.657902Z","shell.execute_reply.started":"2025-05-27T16:14:05.652218Z","shell.execute_reply":"2025-05-27T16:14:05.656967Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def get_user_input(prompt, default=None, required=False, type_cast=str):\n\n    while True:\n        user_input = input(f\"{prompt} [{default}]: \")\n        \n        if user_input == \"\" and required:\n            print(\"This field is required. Please enter a value.\")\n            continue\n        \n        if user_input == \"\" and default is not None:\n            return default\n        \n        if user_input == \"\" and not required:\n            return None\n        \n        try:\n            return type_cast(user_input)\n        except ValueError:\n            print(f\"Invalid input. Please enter a valid {type_cast.__name__}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:06:57.051797Z","iopub.execute_input":"2025-05-27T16:06:57.052100Z","iopub.status.idle":"2025-05-27T16:06:57.066400Z","shell.execute_reply.started":"2025-05-27T16:06:57.052078Z","shell.execute_reply":"2025-05-27T16:06:57.065678Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Load the full dataset first to get labels and number of examples\nfull_dataset = GraphDataset(\"/kaggle/working/hackaton/datasets/A/train.json.gz\", transform=add_zeros)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:06:57.067097Z","iopub.execute_input":"2025-05-27T16:06:57.067302Z","iopub.status.idle":"2025-05-27T16:09:52.947322Z","shell.execute_reply.started":"2025-05-27T16:06:57.067284Z","shell.execute_reply":"2025-05-27T16:09:52.946546Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"script_dir = os.getcwd()\n# device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_checkpoints = 1\nmodel = GINPlusModel(\n        in_dim=8,\n        edge_dim=8,\n        hidden_dim=500,\n        out_classes=6, # Ensure this matches the number of classes in your dataset\n        num_layers=5,\n        dropout=0.1,\n        use_virtual_node=True,\n        confidence_threshold=0.8\n    ).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n\n# Get the labels and number of examples from the full dataset\nall_labels = torch.tensor([data.y.item() for data in full_dataset])\nnum_examples = len(full_dataset)\n\n# Instantiate ncodLoss with the required arguments\n# Make sure the num_classes argument matches the actual number of classes\nraw_ncod = ncodLoss(labels=all_labels, n=num_examples, C=6)\ncriterion = NcodLossWrapper(raw_ncod)\nepochs=5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:14:11.055506Z","iopub.execute_input":"2025-05-27T16:14:11.055812Z","iopub.status.idle":"2025-05-27T16:14:45.983549Z","shell.execute_reply.started":"2025-05-27T16:14:11.055786Z","shell.execute_reply":"2025-05-27T16:14:45.982598Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"test_dir_name = os.path.basename(os.path.dirname(\"/kaggle/working/hackaton/datasets/A/test.json.gz\"))\nlogs_folder = os.path.join(script_dir, \"logs\", test_dir_name)\nlog_file = os.path.join(logs_folder, \"training.log\")\nos.makedirs(os.path.dirname(log_file), exist_ok=True)\nlogging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(message)s')\nlogging.getLogger().addHandler(logging.StreamHandler())\n\ncheckpoint_path = os.path.join(script_dir, \"checkpoints\", f\"model_{test_dir_name}_best.pth\")\ncheckpoints_folder = os.path.join(script_dir, \"checkpoints\", test_dir_name)\nos.makedirs(checkpoints_folder, exist_ok=True)\n","metadata":{"id":"BTYT5jYuChPb","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:14:45.984739Z","iopub.execute_input":"2025-05-27T16:14:45.985032Z","iopub.status.idle":"2025-05-27T16:14:45.990760Z","shell.execute_reply.started":"2025-05-27T16:14:45.985009Z","shell.execute_reply":"2025-05-27T16:14:45.989829Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"if os.path.exists(checkpoint_path) and not os.path.basename(os.path.dirname(\"/kaggle/working/hackaton/datasets/A/test.json.gz\")):\n    model.load_state_dict(torch.load(checkpoint_path))\n    print(f\"Loaded best model from {checkpoint_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:14:45.992325Z","iopub.execute_input":"2025-05-27T16:14:45.992534Z","iopub.status.idle":"2025-05-27T16:14:46.012581Z","shell.execute_reply.started":"2025-05-27T16:14:45.992515Z","shell.execute_reply":"2025-05-27T16:14:46.011906Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"if os.path.basename(os.path.dirname(\"/kaggle/working/hackaton/datasets/A/test.json.gz\")):\n    \n    val_size = int(0.2 * len(full_dataset))\n    train_size = len(full_dataset) - val_size\n\n    \n    generator = torch.Generator().manual_seed(12)\n    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=generator)\n\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n\n    num_epochs = epochs\n    best_val_accuracy = 0.0   \n\n    train_losses = []\n    train_accuracies = []\n    val_losses = []\n    val_accuracies = []\n\n    if num_checkpoints > 1:\n        checkpoint_intervals = [int((i + 1) * num_epochs / num_checkpoints) for i in range(num_checkpoints)]\n    else:\n        checkpoint_intervals = [num_epochs]\n\n    for epoch in range(num_epochs):\n        train_loss, train_acc = train(\n            train_loader, model, optimizer, criterion, device,\n            save_checkpoints=(epoch + 1 in checkpoint_intervals),\n            checkpoint_path=os.path.join(checkpoints_folder, f\"model_{test_dir_name}\"),\n            current_epoch=epoch\n        )\n\n        val_loss,val_acc = evaluate(val_loader, model, device, calculate_accuracy=True)\n\n        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n        logging.info(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n\n        train_losses.append(train_loss)\n        train_accuracies.append(train_acc)\n        val_losses.append(val_loss)\n        val_accuracies.append(val_acc)\n\n        \n        if val_acc > best_val_accuracy:\n            best_val_accuracy = val_acc\n            torch.save(model.state_dict(), checkpoint_path)\n            print(f\"Best model updated and saved at {checkpoint_path}\")\n\n    plot_training_progress(train_losses, train_accuracies, os.path.join(logs_folder, \"plots\"))\n    plot_training_progress(val_losses, val_accuracies, os.path.join(logs_folder, \"plotsVal\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:14:46.013407Z","iopub.execute_input":"2025-05-27T16:14:46.013699Z","iopub.status.idle":"2025-05-27T16:14:46.095747Z","shell.execute_reply.started":"2025-05-27T16:14:46.013666Z","shell.execute_reply":"2025-05-27T16:14:46.094652Z"}},"outputs":[{"name":"stderr","text":"Iterating training graphs:   0%|          | 0/1128 [00:00<?, ?batch/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-1d4513728aee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         train_loss, train_acc = train(\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0msave_checkpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint_intervals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-28-1959091921d1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'idx'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-c59d82f58579>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, batch, labels)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m# Input encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# GIN+ layers with virtual node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2299x32 and 8x500)"],"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (2299x32 and 8x500)","output_type":"error"}],"execution_count":35},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"import gc\ndel train_dataset\ndel train_loader\ndel full_dataset\ndel val_dataset\ndel val_loader\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:10:29.088672Z","iopub.status.idle":"2025-05-27T16:10:29.088979Z","shell.execute_reply":"2025-05-27T16:10:29.088829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = GraphDataset(args.test_path, transform=add_zeros)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n    ","metadata":{"id":"xsXZIj4Mdu3I","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:10:29.089801Z","iopub.status.idle":"2025-05-27T16:10:29.090198Z","shell.execute_reply":"2025-05-27T16:10:29.090030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load(checkpoint_path))\npredictions = evaluate(test_loader, model, device, calculate_accuracy=False)\nsave_predictions(predictions, args.test_path)","metadata":{"id":"x1OnGq_nCmTr","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T16:10:29.091185Z","iopub.status.idle":"2025-05-27T16:10:29.091539Z","shell.execute_reply":"2025-05-27T16:10:29.091384Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}